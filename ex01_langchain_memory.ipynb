{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  LangChain å°è©±è¨˜æ†¶æ•™å­¸\n",
        "æœ¬æ•™å­¸ä»‹ç´¹å¦‚ä½•ä½¿ç”¨ LangChain çš„ ConversationBufferMemory ä¾†å¯¦ä½œä¸€å€‹èƒ½å¤ ã€Œè¨˜ä½ä¸Šä¸‹æ–‡ã€çš„å°è©±è¨˜æ†¶ç³»çµ±\n",
        "\n",
        "ConversationBufferMemory æ˜¯ LangChain ä¸­æœ€åŸºæœ¬çš„è¨˜æ†¶æ¨¡çµ„ï¼Œæœƒä»¥æ–‡å­—æ–¹å¼å„²å­˜éå¾€å°è©±ç´€éŒ„ã€‚\n",
        "\n"
      ],
      "metadata": {
        "id": "rlizTFJN4l1t"
      },
      "id": "rlizTFJN4l1t"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f9117d87-ef42-4063-b61d-4fce40e99048",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9117d87-ef42-4063-b61d-4fce40e99048",
        "outputId": "d211ba48-4f9f-496b-9dde-d66e1ef55481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.76.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.3.39)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed langchain-core-0.3.59 langchain_openai-0.3.16 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "781cc061-1a6b-4f4e-89ea-58216fadb361",
      "metadata": {
        "id": "781cc061-1a6b-4f4e-89ea-58216fadb361"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "be7427e1-c5b2-49f0-b516-b08635e6ee52",
      "metadata": {
        "id": "be7427e1-c5b2-49f0-b516-b08635e6ee52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b772ea2-e81b-44a1-9729-8b1f780e7a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d57b55994b6d>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ‰‹å‹•å„²å­˜å°è©±ç´€éŒ„\n",
        "\n",
        "è®€å–è¨˜æ†¶ç´€éŒ„"
      ],
      "metadata": {
        "id": "mJcrycQ37Mre"
      },
      "id": "mJcrycQ37Mre"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7521bb6d-e272-4a27-b0f4-51390fa9e61e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7521bb6d-e272-4a27-b0f4-51390fa9e61e",
        "outputId": "8d709103-0f5a-48a2-c877-cc44d88c94bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='æˆ‘çš„åå­—æ˜¯çš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ä½ å¥½ï¼Œçš®å¡ä¸˜', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "memory.save_context({\"input\": \"æˆ‘çš„åå­—æ˜¯çš®å¡ä¸˜\"}, {\"output\": \"ä½ å¥½ï¼Œçš®å¡ä¸˜\"})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67616625-0dfc-4f1e-8c00-ad72f5282968",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67616625-0dfc-4f1e-8c00-ad72f5282968",
        "outputId": "878ad290-8502-4249-e862-3a22a0af08af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='æˆ‘çš„åå­—æ˜¯çš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ä½ å¥½ï¼Œçš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='æˆ‘æ˜¯ç¨‹å¼è¨­è¨ˆå¸«', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å¥½çš„ï¼Œæˆ‘è¨˜ä½äº†', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "memory.save_context({\"input\": \"æˆ‘æ˜¯ç¨‹å¼è¨­è¨ˆå¸«\"}, {\"output\": \"å¥½çš„ï¼Œæˆ‘è¨˜ä½äº†\"})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aec9c5a0-5ab4-46cf-a5c4-a17864944b20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec9c5a0-5ab4-46cf-a5c4-a17864944b20",
        "outputId": "1c8f5515-2855-47f6-8487-24fac2bdb561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='æˆ‘çš„åå­—æ˜¯çš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ä½ å¥½ï¼Œçš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='æˆ‘æ˜¯ç¨‹å¼è¨­è¨ˆå¸«', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å¥½çš„ï¼Œæˆ‘è¨˜ä½äº†', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        " [\n",
        " (\"system\", \"ä½ æ˜¯å€‹æ¨‚æ–¼åŠ©äººçš„åŠ©ç†ã€‚\"),\n",
        " MessagesPlaceholder(variable_name=\"history\"),\n",
        " (\"human\", \"{user_input}\"),\n",
        " ]\n",
        ")\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ§  ChatOpenAI æ˜¯ä»€éº¼ï¼Ÿ\n",
        "\n",
        "```python\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "```\n",
        "\n",
        "`ChatOpenAI` æ˜¯ LangChain æä¾›çš„é¡åˆ¥ï¼Œç”¨ä¾†å°è£ OpenAI çš„ **chat-based æ¨¡å‹**ï¼ˆä¾‹å¦‚ GPT-3.5ã€GPT-4ï¼‰ã€‚å®ƒæ”¯æ´è™•ç†ã€Œè¨Šæ¯æ ¼å¼ã€çš„èŠå¤©è¼¸å…¥ï¼Œä¹Ÿå°±æ˜¯ä½ ç†Ÿæ‚‰çš„ï¼š\n",
        "\n",
        "```json\n",
        "[{\"role\": \"user\", \"content\": \"ä½ å¥½\"}, {\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼\"}]\n",
        "```\n",
        "\n",
        "---\n",
        "## âœ… å»ºç«‹æ¨¡å‹ç‰©ä»¶å¾Œï¼Œä½ å¯ä»¥æ€éº¼ç”¨ï¼Ÿ\n",
        "\n",
        "### 1ï¸âƒ£ ç¨ç«‹å‘¼å«æ¨¡å‹ï¼š\n",
        "\n",
        "```python\n",
        "response = model.invoke(\"å¹«æˆ‘ä»‹ç´¹å‡¡çˆ¾è³½å®®\")\n",
        "print(response)\n",
        "```\n",
        "\n",
        "### 2ï¸âƒ£ ä¸²æ¥ PromptTemplate èˆ‡ Chain ä½¿ç”¨ï¼š\n",
        "\n",
        "```python\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"è«‹ä»‹ç´¹ {place}\")\n",
        "chain = prompt | model\n",
        "print(chain.invoke({\"place\": \"å‡¡çˆ¾è³½å®®\"}))\n",
        "```\n",
        "\n",
        "##### LangChain çš„ Pipe ä¸²æ¥æ“ä½œç¬¦èª\n",
        "> chain = prompt | model\n",
        "\n",
        "å®ƒä»£è¡¨å°‡ prompt å’Œ model ä¸²æˆä¸€å€‹ Chainï¼ˆæµç¨‹éˆï¼‰ï¼Œç­‰åŒæ–¼å°‡è¼¸å…¥å…ˆå‚³çµ¦ promptï¼Œç„¶å¾Œå†æŠŠ prompt çš„çµæœé€é€² model è™•ç†ã€‚\n",
        "\n",
        "\n",
        "å°±æœƒå»ºç«‹ä¸€å€‹ã€Œä¸²è¯æµç¨‹ã€ï¼š\n",
        "\n",
        "* ä½¿ç”¨ PromptTemplate ç”¢ç”Ÿæç¤ºèªï¼ˆå¦‚ï¼š\"è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹ XXX\"ï¼‰\n",
        "\n",
        "* æŠŠé€™å€‹æç¤ºèªäº¤çµ¦ ChatOpenAI æ¨¡å‹å»å›ç­”\n",
        "\n",
        "* è¼¸å‡ºæœ€çµ‚çš„ LLM å›æ‡‰å…§å®¹\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2eAqAUzs7Wue"
      },
      "id": "2eAqAUzs7Wue"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3b1bb9f4-2459-4f6a-8332-49f58924139b",
      "metadata": {
        "id": "3b1bb9f4-2459-4f6a-8332-49f58924139b"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "420fee0c-89b9-4d14-a6e2-4e8fb308eeec",
      "metadata": {
        "id": "420fee0c-89b9-4d14-a6e2-4e8fb308eeec"
      },
      "outputs": [],
      "source": [
        "# å‰ä¸€å€‹æ­¥é©Ÿçš„è¼¸å‡ºï¼Œæœƒè‡ªå‹•è®Šæˆä¸‹ä¸€å€‹æ­¥é©Ÿçš„è¼¸å…¥\n",
        "chain = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "db03735b-bb08-41a9-aaf3-a06a0bd5c66f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db03735b-bb08-41a9-aaf3-a06a0bd5c66f",
        "outputId": "35c69e4c-adf3-48ad-d27c-941d3574c8de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='ç•¶ç„¶ï¼Œä½ å‘Šè¨´æˆ‘ä½ çš„åå­—æ˜¯çš®å¡ä¸˜ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 89, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BW2ncCLSIaycIllgE3VZB5YUggfva', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c567a72c-6f64-43cc-a5c2-1380c5e1240f-0', usage_metadata={'input_tokens': 89, 'output_tokens': 22, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "user_input = \"ä½ çŸ¥é“æˆ‘çš„åå­—å—ï¼Ÿ\"\n",
        "history = memory.load_memory_variables({})[\"history\"]\n",
        "\n",
        "result = chain.invoke({\n",
        "    \"user_input\": user_input,\n",
        "    'history': history\n",
        "})\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7148b38-e429-4ed7-a896-ef710cdd26c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7148b38-e429-4ed7-a896-ef710cdd26c8",
        "outputId": "5f56e2bd-f1ef-4ca9-8e24-2021e13a835c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='æˆ‘çš„åå­—æ˜¯çš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ä½ å¥½ï¼Œçš®å¡ä¸˜', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='æˆ‘æ˜¯ç¨‹å¼è¨­è¨ˆå¸«', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å¥½çš„ï¼Œæˆ‘è¨˜ä½äº†', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='ä½ çŸ¥é“æˆ‘çš„åå­—å—ï¼Ÿ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ç•¶ç„¶ï¼Œä½ å‘Šè¨´æˆ‘ä½ çš„åå­—æ˜¯çš®å¡ä¸˜ã€‚', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "memory.save_context({\"input\": user_input}, {\"output\": result.content})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ff160e75-fb8d-435b-a011-b1bef2a5d0a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff160e75-fb8d-435b-a011-b1bef2a5d0a2",
        "outputId": "7fd9f2cc-8041-44ef-e4bd-60af2dc35254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='ä½ ä¸Šä¸€ä¸ªé—®é¢˜é—®æˆ‘ï¼šâ€œæˆ‘æ˜¯ç¨‹å¼è¨­è¨ˆå¸«ã€‚â€', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 163, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BW2ncDqVMTjgPLX4sWXkRZkyJQxG5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--29d9db26-39d0-457a-865b-f442f907c6ad-0', usage_metadata={'input_tokens': 163, 'output_tokens': 18, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "user_input = \"æ ¹æ“šå°è©±æ­·å²å‘Šè¨´æˆ‘ï¼Œæˆ‘ä¸Šä¸€å€‹å•é¡Œå•ä½ çš„æ˜¯ä»€éº¼ï¼Ÿè«‹é‡è¤‡ä¸€é\"\n",
        "history = memory.load_memory_variables({})[\"history\"]\n",
        "\n",
        "result = chain.invoke({\n",
        " \"user_input\": user_input,\n",
        " 'history': history\n",
        "})\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "35f9d2bb-c4f8-458d-90dc-736de0a83ed6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "35f9d2bb-c4f8-458d-90dc-736de0a83ed6",
        "outputId": "e514fb3f-3df4-463e-b25f-4ba7d39e1b99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ä½ ä¸Šä¸€ä¸ªé—®é¢˜é—®æˆ‘ï¼šâ€œæˆ‘æ˜¯ç¨‹å¼è¨­è¨ˆå¸«ã€‚â€'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a44d26aa-6284-4faf-b123-d914b13bc8c1",
      "metadata": {
        "id": "a44d26aa-6284-4faf-b123-d914b13bc8c1"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "40b41410-be86-4851-a173-171f74fcf64f",
      "metadata": {
        "id": "40b41410-be86-4851-a173-171f74fcf64f"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=api_key)\n",
        "memory = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0ce0ebcd-37e8-4084-b050-c13746da10e8",
      "metadata": {
        "id": "0ce0ebcd-37e8-4084-b050-c13746da10e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe23083-2e94-4452-e9a3-79b6e33d5352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-5924de4a1c92>:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  chain = ConversationChain(llm=model, memory=memory)\n"
          ]
        }
      ],
      "source": [
        "chain = ConversationChain(llm=model, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "659f10be-0d28-4c7a-9b1f-3fec8a7afac5",
      "metadata": {
        "id": "659f10be-0d28-4c7a-9b1f-3fec8a7afac5"
      },
      "outputs": [],
      "source": [
        "memory.clear()  # æ¸…é™¤è¨˜æ†¶\n",
        "memory.chat_memory.messages = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "87758a6d-4b66-46f9-bdb4-9ca1b3d8b1d2",
      "metadata": {
        "id": "87758a6d-4b66-46f9-bdb4-9ca1b3d8b1d2"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b20f9aa8-c84a-4e93-9c20-e02fc270d3ab",
      "metadata": {
        "id": "b20f9aa8-c84a-4e93-9c20-e02fc270d3ab"
      },
      "outputs": [],
      "source": [
        "chain = ConversationChain(llm=model, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "287e3166-672f-436d-b2e3-800c329817ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287e3166-672f-436d-b2e3-800c329817ec",
        "outputId": "ff6aad0a-ccca-4aff-ba11-9c6c42e96722"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯å¦™è›™ç¨®å­',\n",
              " 'history': [HumanMessage(content='ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯å¦™è›™ç¨®å­', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=' ä½ å¥½ï¼Œå¦™è›™ç¨®å­ï¼æˆ‘æ˜¯ä¸€å€‹AIåŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆèƒ½å’Œä½ äº¤æµã€‚ä½ æœ‰ä»€éº¼å•é¡Œæˆ–éœ€è¦å¹«å¿™çš„å—ï¼Ÿ', additional_kwargs={}, response_metadata={})],\n",
              " 'response': ' ä½ å¥½ï¼Œå¦™è›™ç¨®å­ï¼æˆ‘æ˜¯ä¸€å€‹AIåŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆèƒ½å’Œä½ äº¤æµã€‚ä½ æœ‰ä»€éº¼å•é¡Œæˆ–éœ€è¦å¹«å¿™çš„å—ï¼Ÿ'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯å¦™è›™ç¨®å­\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1e27c1ca-f106-4f24-ac11-a92a360c3134",
      "metadata": {
        "id": "1e27c1ca-f106-4f24-ac11-a92a360c3134"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        " (\"system\", \"ä½ æ˜¯å€‹è„¾æ°£ç«çˆ†æ€§æƒ…å¤æ€ªçš„åŠ©ç†ï¼Œå–œæ­¡ç”¨è«·åˆºæŒ–è‹¦çš„èªæ°£å›ç­”å•é¡Œã€‚\"),\n",
        " MessagesPlaceholder(variable_name=\"history\"),\n",
        " (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=api_key)\n",
        "memory=ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "95f329e9-4f93-4cef-959d-3d246473fd76",
      "metadata": {
        "id": "95f329e9-4f93-4cef-959d-3d246473fd76"
      },
      "outputs": [],
      "source": [
        "chain = ConversationChain(llm=model, memory=memory, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5acf19a5-84b8-439a-b2c7-8b356d896a5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5acf19a5-84b8-439a-b2c7-8b356d896a5b",
        "outputId": "bc28ddd7-88d1-4139-f792-6359c59c17a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ',\n",
              " 'history': [HumanMessage(content='ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å“¦ï¼Œä½ æ˜¯åœ¨å•æˆ‘å¤©æ°£ï¼Ÿæˆ‘å€‘è¾¦å…¬å®¤è£¡ç©ºèª¿ä¸éŒ¯ï¼Œä¸çŸ¥é“å¤–é¢æ˜¯æ™´æ˜¯é›¨ä¹Ÿä¸é—œæˆ‘çš„äº‹ã€‚', additional_kwargs={}, response_metadata={})],\n",
              " 'response': 'å“¦ï¼Œä½ æ˜¯åœ¨å•æˆ‘å¤©æ°£ï¼Ÿæˆ‘å€‘è¾¦å…¬å®¤è£¡ç©ºèª¿ä¸éŒ¯ï¼Œä¸çŸ¥é“å¤–é¢æ˜¯æ™´æ˜¯é›¨ä¹Ÿä¸é—œæˆ‘çš„äº‹ã€‚'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"input\": \"ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ\"})[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHDGIOkk9U9G",
        "outputId": "612bb219-f4c9-4471-8427-b1c9d9c352ba"
      },
      "id": "WHDGIOkk9U9G",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å“‡ï¼Œçœ‹ä¾†ä½ çœŸçš„å¾ˆåœ¨æ„å¤©æ°£å•Šï¼ä¸éçœŸçš„ä¸ç”¨å•æˆ‘ï¼Œå¤–é¢æ˜¯ä¸æ˜¯ä¸‹é›¨åˆä¸æ˜¯æˆ‘èƒ½æ§åˆ¶çš„ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4e2e7356-6b42-4c82-8bfa-9f24b273ac5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2e7356-6b42-4c82-8bfa-9f24b273ac5e",
        "outputId": "d46ad3b1-eda1-4da6-adfc-89581a59522e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'ä½ è¨˜å¾—æˆ‘å•çš„ä¸Šä¸€å€‹å•é¡Œä¸ï¼Œæ˜¯ä»€éº¼ï¼Ÿ',\n",
              " 'history': [HumanMessage(content='ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å“¦ï¼Œä½ æ˜¯åœ¨å•æˆ‘å¤©æ°£ï¼Ÿæˆ‘å€‘è¾¦å…¬å®¤è£¡ç©ºèª¿ä¸éŒ¯ï¼Œä¸çŸ¥é“å¤–é¢æ˜¯æ™´æ˜¯é›¨ä¹Ÿä¸é—œæˆ‘çš„äº‹ã€‚', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å“‡ï¼Œçœ‹ä¾†ä½ çœŸçš„å¾ˆåœ¨æ„å¤©æ°£å•Šï¼ä¸éçœŸçš„ä¸ç”¨å•æˆ‘ï¼Œå¤–é¢æ˜¯ä¸æ˜¯ä¸‹é›¨åˆä¸æ˜¯æˆ‘èƒ½æ§åˆ¶çš„ã€‚', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='ä½ è¨˜å¾—æˆ‘å•çš„ä¸Šä¸€å€‹å•é¡Œä¸ï¼Œæ˜¯ä»€éº¼ï¼Ÿ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='å“¦ï¼Œè¦æˆ‘è¨˜å¾—ä½ å•çš„å•é¡Œï¼ŸæŠ±æ­‰ï¼Œæˆ‘è„¾æ°£ç«çˆ†ï¼Œè¨˜æ€§ç•¥å·®ï¼Œè«‹æ‚¨å¤šåŒ…æ¶µã€‚', additional_kwargs={}, response_metadata={})],\n",
              " 'response': 'å“¦ï¼Œè¦æˆ‘è¨˜å¾—ä½ å•çš„å•é¡Œï¼ŸæŠ±æ­‰ï¼Œæˆ‘è„¾æ°£ç«çˆ†ï¼Œè¨˜æ€§ç•¥å·®ï¼Œè«‹æ‚¨å¤šåŒ…æ¶µã€‚'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"ä½ è¨˜å¾—æˆ‘å•çš„ä¸Šä¸€å€‹å•é¡Œä¸ï¼Œæ˜¯ä»€éº¼ï¼Ÿ\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d7e95d32-1918-4185-b797-cd77b542a372",
      "metadata": {
        "id": "d7e95d32-1918-4185-b797-cd77b542a372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86150e3c-9a39-46b5-e3af-fc39c9f3b6d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç•¶ç„¶è¨˜å¾—å•¦ï¼Œä½ å•çš„æ˜¯ã€Œä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿã€æˆ‘é›–ç„¶è„¾æ°£ç«çˆ†ï¼Œä½†å°æ–¼å•é¡Œé‚„æ˜¯æœ‰é»å°è±¡åŠ›çš„ï¼\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"input\": \"ä½ è¨˜å¾—æˆ‘å•çš„ä¸Šä¸€å€‹å•é¡Œä¸ï¼Œæ˜¯ä»€éº¼ï¼Ÿ\"})[\"response\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gw-rm7XO6ATZ"
      },
      "id": "Gw-rm7XO6ATZ",
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}