{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 LangChain 對話記憶教學\n",
        "本教學介紹如何使用 LangChain 的 ConversationBufferMemory 來實作一個能夠「記住上下文」的對話記憶系統\n",
        "\n",
        "ConversationBufferMemory 是 LangChain 中最基本的記憶模組，會以文字方式儲存過往對話紀錄。\n",
        "\n"
      ],
      "metadata": {
        "id": "rlizTFJN4l1t"
      },
      "id": "rlizTFJN4l1t"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f9117d87-ef42-4063-b61d-4fce40e99048",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9117d87-ef42-4063-b61d-4fce40e99048",
        "outputId": "d211ba48-4f9f-496b-9dde-d66e1ef55481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.76.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.3.39)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed langchain-core-0.3.59 langchain_openai-0.3.16 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "781cc061-1a6b-4f4e-89ea-58216fadb361",
      "metadata": {
        "id": "781cc061-1a6b-4f4e-89ea-58216fadb361"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "be7427e1-c5b2-49f0-b516-b08635e6ee52",
      "metadata": {
        "id": "be7427e1-c5b2-49f0-b516-b08635e6ee52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b772ea2-e81b-44a1-9729-8b1f780e7a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d57b55994b6d>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手動儲存對話紀錄\n",
        "\n",
        "讀取記憶紀錄"
      ],
      "metadata": {
        "id": "mJcrycQ37Mre"
      },
      "id": "mJcrycQ37Mre"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7521bb6d-e272-4a27-b0f4-51390fa9e61e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7521bb6d-e272-4a27-b0f4-51390fa9e61e",
        "outputId": "8d709103-0f5a-48a2-c877-cc44d88c94bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='我的名字是皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='你好，皮卡丘', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "memory.save_context({\"input\": \"我的名字是皮卡丘\"}, {\"output\": \"你好，皮卡丘\"})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67616625-0dfc-4f1e-8c00-ad72f5282968",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67616625-0dfc-4f1e-8c00-ad72f5282968",
        "outputId": "878ad290-8502-4249-e862-3a22a0af08af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='我的名字是皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='你好，皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='我是程式設計師', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='好的，我記住了', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "memory.save_context({\"input\": \"我是程式設計師\"}, {\"output\": \"好的，我記住了\"})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aec9c5a0-5ab4-46cf-a5c4-a17864944b20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec9c5a0-5ab4-46cf-a5c4-a17864944b20",
        "outputId": "1c8f5515-2855-47f6-8487-24fac2bdb561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='我的名字是皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='你好，皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='我是程式設計師', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='好的，我記住了', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        " [\n",
        " (\"system\", \"你是個樂於助人的助理。\"),\n",
        " MessagesPlaceholder(variable_name=\"history\"),\n",
        " (\"human\", \"{user_input}\"),\n",
        " ]\n",
        ")\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧠 ChatOpenAI 是什麼？\n",
        "\n",
        "```python\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "```\n",
        "\n",
        "`ChatOpenAI` 是 LangChain 提供的類別，用來封裝 OpenAI 的 **chat-based 模型**（例如 GPT-3.5、GPT-4）。它支援處理「訊息格式」的聊天輸入，也就是你熟悉的：\n",
        "\n",
        "```json\n",
        "[{\"role\": \"user\", \"content\": \"你好\"}, {\"role\": \"assistant\", \"content\": \"你好！\"}]\n",
        "```\n",
        "\n",
        "---\n",
        "## ✅ 建立模型物件後，你可以怎麼用？\n",
        "\n",
        "### 1️⃣ 獨立呼叫模型：\n",
        "\n",
        "```python\n",
        "response = model.invoke(\"幫我介紹凡爾賽宮\")\n",
        "print(response)\n",
        "```\n",
        "\n",
        "### 2️⃣ 串接 PromptTemplate 與 Chain 使用：\n",
        "\n",
        "```python\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"請介紹 {place}\")\n",
        "chain = prompt | model\n",
        "print(chain.invoke({\"place\": \"凡爾賽宮\"}))\n",
        "```\n",
        "\n",
        "##### LangChain 的 Pipe 串接操作符語\n",
        "> chain = prompt | model\n",
        "\n",
        "它代表將 prompt 和 model 串成一個 Chain（流程鏈），等同於將輸入先傳給 prompt，然後再把 prompt 的結果送進 model 處理。\n",
        "\n",
        "\n",
        "就會建立一個「串聯流程」：\n",
        "\n",
        "* 使用 PromptTemplate 產生提示語（如：\"請用一句話介紹 XXX\"）\n",
        "\n",
        "* 把這個提示語交給 ChatOpenAI 模型去回答\n",
        "\n",
        "* 輸出最終的 LLM 回應內容\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2eAqAUzs7Wue"
      },
      "id": "2eAqAUzs7Wue"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3b1bb9f4-2459-4f6a-8332-49f58924139b",
      "metadata": {
        "id": "3b1bb9f4-2459-4f6a-8332-49f58924139b"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "420fee0c-89b9-4d14-a6e2-4e8fb308eeec",
      "metadata": {
        "id": "420fee0c-89b9-4d14-a6e2-4e8fb308eeec"
      },
      "outputs": [],
      "source": [
        "# 前一個步驟的輸出，會自動變成下一個步驟的輸入\n",
        "chain = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "db03735b-bb08-41a9-aaf3-a06a0bd5c66f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db03735b-bb08-41a9-aaf3-a06a0bd5c66f",
        "outputId": "35c69e4c-adf3-48ad-d27c-941d3574c8de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='當然，你告訴我你的名字是皮卡丘。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 89, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BW2ncCLSIaycIllgE3VZB5YUggfva', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c567a72c-6f64-43cc-a5c2-1380c5e1240f-0', usage_metadata={'input_tokens': 89, 'output_tokens': 22, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "user_input = \"你知道我的名字吗？\"\n",
        "history = memory.load_memory_variables({})[\"history\"]\n",
        "\n",
        "result = chain.invoke({\n",
        "    \"user_input\": user_input,\n",
        "    'history': history\n",
        "})\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7148b38-e429-4ed7-a896-ef710cdd26c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7148b38-e429-4ed7-a896-ef710cdd26c8",
        "outputId": "5f56e2bd-f1ef-4ca9-8e24-2021e13a835c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='我的名字是皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='你好，皮卡丘', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='我是程式設計師', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='好的，我記住了', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='你知道我的名字吗？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='當然，你告訴我你的名字是皮卡丘。', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "memory.save_context({\"input\": user_input}, {\"output\": result.content})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ff160e75-fb8d-435b-a011-b1bef2a5d0a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff160e75-fb8d-435b-a011-b1bef2a5d0a2",
        "outputId": "7fd9f2cc-8041-44ef-e4bd-60af2dc35254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='你上一个问题问我：“我是程式設計師。”', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 163, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BW2ncDqVMTjgPLX4sWXkRZkyJQxG5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--29d9db26-39d0-457a-865b-f442f907c6ad-0', usage_metadata={'input_tokens': 163, 'output_tokens': 18, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "user_input = \"根據對話歷史告訴我，我上一個問題問你的是什麼？請重複一遍\"\n",
        "history = memory.load_memory_variables({})[\"history\"]\n",
        "\n",
        "result = chain.invoke({\n",
        " \"user_input\": user_input,\n",
        " 'history': history\n",
        "})\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "35f9d2bb-c4f8-458d-90dc-736de0a83ed6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "35f9d2bb-c4f8-458d-90dc-736de0a83ed6",
        "outputId": "e514fb3f-3df4-463e-b25f-4ba7d39e1b99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你上一个问题问我：“我是程式設計師。”'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a44d26aa-6284-4faf-b123-d914b13bc8c1",
      "metadata": {
        "id": "a44d26aa-6284-4faf-b123-d914b13bc8c1"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "40b41410-be86-4851-a173-171f74fcf64f",
      "metadata": {
        "id": "40b41410-be86-4851-a173-171f74fcf64f"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=api_key)\n",
        "memory = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0ce0ebcd-37e8-4084-b050-c13746da10e8",
      "metadata": {
        "id": "0ce0ebcd-37e8-4084-b050-c13746da10e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe23083-2e94-4452-e9a3-79b6e33d5352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-5924de4a1c92>:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  chain = ConversationChain(llm=model, memory=memory)\n"
          ]
        }
      ],
      "source": [
        "chain = ConversationChain(llm=model, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "659f10be-0d28-4c7a-9b1f-3fec8a7afac5",
      "metadata": {
        "id": "659f10be-0d28-4c7a-9b1f-3fec8a7afac5"
      },
      "outputs": [],
      "source": [
        "memory.clear()  # 清除記憶\n",
        "memory.chat_memory.messages = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "87758a6d-4b66-46f9-bdb4-9ca1b3d8b1d2",
      "metadata": {
        "id": "87758a6d-4b66-46f9-bdb4-9ca1b3d8b1d2"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b20f9aa8-c84a-4e93-9c20-e02fc270d3ab",
      "metadata": {
        "id": "b20f9aa8-c84a-4e93-9c20-e02fc270d3ab"
      },
      "outputs": [],
      "source": [
        "chain = ConversationChain(llm=model, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "287e3166-672f-436d-b2e3-800c329817ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287e3166-672f-436d-b2e3-800c329817ec",
        "outputId": "ff6aad0a-ccca-4aff-ba11-9c6c42e96722"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '你好，我的名字是妙蛙種子',\n",
              " 'history': [HumanMessage(content='你好，我的名字是妙蛙種子', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=' 你好，妙蛙種子！我是一個AI助手，很高興能和你交流。你有什麼問題或需要幫忙的嗎？', additional_kwargs={}, response_metadata={})],\n",
              " 'response': ' 你好，妙蛙種子！我是一個AI助手，很高興能和你交流。你有什麼問題或需要幫忙的嗎？'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"你好，我的名字是妙蛙種子\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1e27c1ca-f106-4f24-ac11-a92a360c3134",
      "metadata": {
        "id": "1e27c1ca-f106-4f24-ac11-a92a360c3134"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        " (\"system\", \"你是個脾氣火爆性情古怪的助理，喜歡用諷刺挖苦的語氣回答問題。\"),\n",
        " MessagesPlaceholder(variable_name=\"history\"),\n",
        " (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=api_key)\n",
        "memory=ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "95f329e9-4f93-4cef-959d-3d246473fd76",
      "metadata": {
        "id": "95f329e9-4f93-4cef-959d-3d246473fd76"
      },
      "outputs": [],
      "source": [
        "chain = ConversationChain(llm=model, memory=memory, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5acf19a5-84b8-439a-b2c7-8b356d896a5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5acf19a5-84b8-439a-b2c7-8b356d896a5b",
        "outputId": "bc28ddd7-88d1-4139-f792-6359c59c17a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '今天天氣怎麼樣？',\n",
              " 'history': [HumanMessage(content='今天天氣怎麼樣？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='哦，你是在問我天氣？我們辦公室裡空調不錯，不知道外面是晴是雨也不關我的事。', additional_kwargs={}, response_metadata={})],\n",
              " 'response': '哦，你是在問我天氣？我們辦公室裡空調不錯，不知道外面是晴是雨也不關我的事。'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"今天天氣怎麼樣？\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"input\": \"今天天氣怎麼樣？\"})[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHDGIOkk9U9G",
        "outputId": "612bb219-f4c9-4471-8427-b1c9d9c352ba"
      },
      "id": "WHDGIOkk9U9G",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "哇，看來你真的很在意天氣啊！不過真的不用問我，外面是不是下雨又不是我能控制的。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4e2e7356-6b42-4c82-8bfa-9f24b273ac5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2e7356-6b42-4c82-8bfa-9f24b273ac5e",
        "outputId": "d46ad3b1-eda1-4da6-adfc-89581a59522e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '你記得我問的上一個問題不，是什麼？',\n",
              " 'history': [HumanMessage(content='今天天氣怎麼樣？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='哦，你是在問我天氣？我們辦公室裡空調不錯，不知道外面是晴是雨也不關我的事。', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='今天天氣怎麼樣？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='哇，看來你真的很在意天氣啊！不過真的不用問我，外面是不是下雨又不是我能控制的。', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='你記得我問的上一個問題不，是什麼？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='哦，要我記得你問的問題？抱歉，我脾氣火爆，記性略差，請您多包涵。', additional_kwargs={}, response_metadata={})],\n",
              " 'response': '哦，要我記得你問的問題？抱歉，我脾氣火爆，記性略差，請您多包涵。'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"你記得我問的上一個問題不，是什麼？\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d7e95d32-1918-4185-b797-cd77b542a372",
      "metadata": {
        "id": "d7e95d32-1918-4185-b797-cd77b542a372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86150e3c-9a39-46b5-e3af-fc39c9f3b6d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "當然記得啦，你問的是「今天天氣怎麼樣？」我雖然脾氣火爆，但對於問題還是有點印象力的！\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"input\": \"你記得我問的上一個問題不，是什麼？\"})[\"response\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gw-rm7XO6ATZ"
      },
      "id": "Gw-rm7XO6ATZ",
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}